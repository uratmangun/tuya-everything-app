# Session 17: Mic Audio Streaming from DevKit to Web App

## Summary
Fixed mic audio streaming from T5AI DevKit to web application. The DevKit captures audio from its onboard microphone and streams it via TCP to the server, which then streams it to web clients via HTTP chunked transfer. Web clients use Web Audio API to play the raw PCM audio.

## Issues Fixed

### 1. JavaScript Syntax Error in index.html
- **Problem**: `Uncaught SyntaxError: Unexpected token '}' (at (index):812:9)`
- **Cause**: Orphaned code left after `handleAudioData` function was simplified - dead code (PCM conversion and `playNextAudioChunk`) was outside any function
- **Fix**: Removed orphaned code blocks and unused `playNextAudioChunk` function

### 2. FFmpeg Audio Streaming Issues
- **Problem**: Audio was garbled and took ~1 minute to start
- **Cause**: FFmpeg buffering and MP3 encoding latency
- **Attempted fixes**:
  - Added low-latency FFmpeg flags (`-fflags nobuffer`, `-flags low_delay`, `-reservoir 0`)
  - FFmpeg kept closing immediately (code 0) when no input data initially
- **Final solution**: Removed FFmpeg entirely, switched to raw PCM streaming

### 3. WAV Streaming Didn't Work
- **Problem**: HTML5 `<audio>` element doesn't handle streaming WAV well - expects complete file
- **Fix**: Switched to Web Audio API for direct PCM playback

### 4. Duplicate Audio Players in UI
- **Problem**: Two audio player elements showing in the mic status section
- **Fix**: Removed duplicate HTML elements

### 5. Keep-Alive Ping Interrupting Audio
- **Problem**: Server was pinging DevKit every 60 seconds, which seemed to interrupt audio streaming
- **Fix**: Removed automatic keep-alive ping - user can ping manually via web UI

### 6. Garbled Audio Playback
- **Problem**: Audio chunks were playing immediately with `source.start()` without scheduling, causing overlapping audio
- **Fix**: Implemented proper audio scheduling using `nextPlayTime` to play buffers sequentially

## Architecture

```
DevKit (T5AI)                    VPS Server                      Web Browser
┌─────────────┐                 ┌─────────────┐                 ┌─────────────┐
│ Microphone  │                 │ TCP Server  │                 │ Web Audio   │
│     ↓       │   TCP:5000      │  (port 5000)│   HTTP:3000     │    API      │
│ PCM 16-bit  │ ──────────────→ │     ↓       │ ──────────────→ │     ↓       │
│ 8kHz mono   │  audio:prefix   │ HTTP Stream │  raw PCM chunks │ Float32     │
│ 640 bytes   │  + binary data  │ /audio-stream                 │ AudioBuffer │
└─────────────┘                 └─────────────┘                 └─────────────┘
```

## Key Code Changes

### Server (server.js)

Simplified audio streaming - raw PCM chunks via HTTP:

```javascript
function broadcastAudioToWeb(audioData) {
    audioClients.forEach(res => {
        try { 
            res.write(audioData); 
        } catch(e) { 
            audioClients.delete(res); 
        }
    });
}

app.get('/audio-stream', (req, res) => {
    res.setHeader('Content-Type', 'application/octet-stream');
    res.setHeader('Cache-Control', 'no-cache, no-store');
    res.setHeader('Connection', 'keep-alive');
    res.setHeader('X-Audio-Format', 'pcm-s16le-8000hz-mono');
    
    audioClients.add(res);
    
    req.on('close', () => {
        audioClients.delete(res);
    });
});
```

### Client (index.html)

Web Audio API streaming with proper scheduling:

```javascript
let audioContext = null;
let micStreamActive = false;
let micAbortController = null;
let nextPlayTime = 0;

async function startMicStream() {
    if (micStreamActive) return;
    
    // Create AudioContext
    if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 8000 });
    }
    
    if (audioContext.state === 'suspended') {
        await audioContext.resume();
    }
    
    micStreamActive = true;
    micAbortController = new AbortController();
    nextPlayTime = audioContext.currentTime;
    
    // Fetch the audio stream
    const response = await fetch('/audio-stream', { signal: micAbortController.signal });
    const reader = response.body.getReader();
    
    let pcmBuffer = new Uint8Array(0);
    const CHUNK_SIZE = 1600; // 100ms of audio at 8kHz 16-bit mono
    
    while (micStreamActive) {
        const { done, value } = await reader.read();
        if (done) break;
        
        // Append new data to buffer
        const newBuffer = new Uint8Array(pcmBuffer.length + value.length);
        newBuffer.set(pcmBuffer);
        newBuffer.set(value, pcmBuffer.length);
        pcmBuffer = newBuffer;
        
        // Process complete chunks
        while (pcmBuffer.length >= CHUNK_SIZE) {
            const chunk = pcmBuffer.slice(0, CHUNK_SIZE);
            pcmBuffer = pcmBuffer.slice(CHUNK_SIZE);
            
            // Convert PCM 16-bit to Float32
            const samples = new Int16Array(chunk.buffer, chunk.byteOffset, chunk.length / 2);
            const floatSamples = new Float32Array(samples.length);
            for (let i = 0; i < samples.length; i++) {
                floatSamples[i] = samples[i] / 32768.0;
            }
            
            // Create audio buffer
            const audioBuffer = audioContext.createBuffer(1, floatSamples.length, 8000);
            audioBuffer.getChannelData(0).set(floatSamples);
            
            // Schedule playback
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            
            // Catch up if behind
            if (nextPlayTime < audioContext.currentTime) {
                nextPlayTime = audioContext.currentTime;
            }
            
            source.start(nextPlayTime);
            nextPlayTime += audioBuffer.duration;
        }
    }
}

function stopMicStream() {
    if (micAbortController) {
        micAbortController.abort();
        micAbortController = null;
    }
    micStreamActive = false;
}
```

### DevKit Firmware (mic_streaming.c)

Audio format from DevKit:
- PCM 16-bit signed little-endian
- 8000 Hz sample rate
- Mono (1 channel)
- 640 bytes per TCP message (40ms of audio, 2 frames of 320 bytes each)
- Message format: `audio:` prefix (6 bytes) + binary PCM data

## Research: Mediabunny Library

Reviewed `/home/uratmangun/CascadeProjects/TuyaOpen/docs/mediabunny-llms.txt` - a JavaScript library for media file handling that could be useful for:
- `ReadableStreamSource` - for streaming audio input
- `AudioBufferSink` - converts audio samples to AudioBuffer for Web Audio API
- Supports `pcm-s16` format natively

However, for this use case, direct Web Audio API was simpler and sufficient.

## Files Modified

1. `/home/uratmangun/CascadeProjects/TuyaOpen/webapp/server.js`
   - Removed FFmpeg streaming
   - Simplified to raw PCM HTTP streaming
   - Removed automatic keep-alive ping

2. `/home/uratmangun/CascadeProjects/TuyaOpen/webapp/public/index.html`
   - Fixed syntax error (removed orphaned code)
   - Removed duplicate audio player elements
   - Replaced HTML5 audio element with Web Audio API controls
   - Added proper audio scheduling for smooth playback

3. `/home/uratmangun/CascadeProjects/TuyaOpen/apps/tuya_cloud/object_detection/src/mic_streaming.c`
   - Added debug logging to mic callback and streaming task

## Deployment Commands

```bash
# Copy files and rebuild
scp -r /home/uratmangun/CascadeProjects/TuyaOpen/webapp/* ubuntu@YOUR_TAILSCALE_IP:~/tuya-webapp/

# Rebuild and restart container
ssh ubuntu@YOUR_TAILSCALE_IP "cd ~/tuya-webapp && podman build -t tuya-webapp:latest . && podman stop tuya-webapp; podman rm tuya-webapp; podman run -d --name tuya-webapp --network tunnel-net --env-file .env.production -p 3000:3000 -p 5000:5000 --restart unless-stopped tuya-webapp:latest"

# Check logs
ssh ubuntu@YOUR_TAILSCALE_IP "podman logs tuya-webapp 2>&1 | tail -50"
```

## Status

- ✅ DevKit sends mic audio data via TCP (640 bytes every 40ms)
- ✅ Server receives and forwards to HTTP clients
- ✅ Web client connects and receives audio stream
- ✅ Web Audio API plays audio with proper scheduling
- ⚠️ Audio quality may still need tuning (latency, buffer sizes)
